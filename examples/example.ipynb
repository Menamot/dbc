{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-25T10:00:57.972203Z",
     "start_time": "2025-09-25T10:00:56.641267Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from sklearn import datasets\n",
    "\n",
    "from dbc.main import KmeansDiscreteBayesianClassifier, KmeansDiscreteMinimaxClassifier, \\\n",
    "    CmeansDiscreteBayesianClassifier, DecisionTreeDiscreteBayesianClassifier, DecisionTreeDiscreteMinimaxClassifier, DiscriminativeDiscreteBayesianClassifier, DiscriminativeMinmaxClassifier\n",
    "from dbc.utils import compute_conditional_risk\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T10:00:57.980721Z",
     "start_time": "2025-09-25T10:00:57.976721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate data\n",
    "X_train, y_train = datasets.make_blobs(n_samples=[125 * 5, 125 * 2], n_features=2, centers=[(9.5, 10), (10, 9.4)],\n",
    "                                       cluster_std=[[0.6, 0.6], [0.35, 0.3]], shuffle=True)"
   ],
   "id": "77e00022e68dc182",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T10:01:05.526956Z",
     "start_time": "2025-09-25T10:00:58.337782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Kmeans Discrete Bayesian Classifier with 10 clusters and a set random state for reproducibility\n",
    "DBC_kmeans = DiscriminativeDiscreteBayesianClassifier(n_clusters=15, n_epochs=300)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "DBC_kmeans.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = DBC_kmeans.predict(X_train)\n",
    "\n",
    "# Compute the conditional risk based on the true labels and predicted labels\n",
    "conditional_risk = compute_conditional_risk(y_train, y_pred)\n",
    "print(f'Class condition risk: \\n{conditional_risk[0]}')\n",
    "print(f'\\nConfusion matrix: \\n{conditional_risk[1]}')"
   ],
   "id": "bdd072c80f3b1c39",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m DBC_kmeans \u001B[38;5;241m=\u001B[39m DiscriminativeDiscreteBayesianClassifier(n_clusters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m, n_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Fit the classifier using the training data\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m DBC_kmeans\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Predict the labels for the training data\u001B[39;00m\n\u001B[0;32m      8\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m DBC_kmeans\u001B[38;5;241m.\u001B[39mpredict(X_train)\n",
      "File \u001B[1;32mD:\\project\\dbc\\dbc\\main.py:93\u001B[0m, in \u001B[0;36mBaseDiscreteBayesianClassifier.fit\u001B[1;34m(self, X, y, loss_function)\u001B[0m\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid loss_function\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprior \u001B[38;5;241m=\u001B[39m compute_prior(y_encoded, n_classes)\n\u001B[1;32m---> 93\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_discretization(X, y_encoded, n_classes)\n",
      "File \u001B[1;32mD:\\project\\dbc\\dbc\\main.py:1564\u001B[0m, in \u001B[0;36m_DiscriminativeNNDiscretization._fit_discretization\u001B[1;34m(self, X, y, n_classes)\u001B[0m\n\u001B[0;32m   1562\u001B[0m X\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1563\u001B[0m y\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1564\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmembership_degree \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiscretization_model(X)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m   1565\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp_hat \u001B[38;5;241m=\u001B[39m compute_p_hat_with_degree(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmembership_degree, y\u001B[38;5;241m.\u001B[39mnumpy(), n_classes)\n\u001B[0;32m   1566\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprior_attribute \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprior_star\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mD:\\program\\Miniconda3\\envs\\RML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\program\\Miniconda3\\envs\\RML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\project\\dbc\\dbc\\main.py:1481\u001B[0m, in \u001B[0;36mDiscriminativeNN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m   1479\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m   1480\u001B[0m     \u001B[38;5;66;03m# q(Z|X)\u001B[39;00m\n\u001B[1;32m-> 1481\u001B[0m     profile_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(x)\n\u001B[0;32m   1482\u001B[0m     q_z_given_x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(profile_logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# [B, T]\u001B[39;00m\n\u001B[0;32m   1484\u001B[0m     \u001B[38;5;66;03m# Profile 后验\u001B[39;00m\n",
      "File \u001B[1;32mD:\\program\\Miniconda3\\envs\\RML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\program\\Miniconda3\\envs\\RML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\program\\Miniconda3\\envs\\RML\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 244\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\program\\Miniconda3\\envs\\RML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\program\\Miniconda3\\envs\\RML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\program\\Miniconda3\\envs\\RML\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot decision boundaries and probability contours for DBC, PDBC with hard clustering, and PDBC with soft clustering\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z1 = DBC_kmeans.predict_prob(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z1 = Z1[:, 1].reshape(xx.shape)\n",
    "\n",
    "\n",
    "class0_indices = (y_train == 0)\n",
    "class1_indices = (y_train == 1)\n",
    "for i in range(3):\n",
    "    ax[i].scatter(X_train[class0_indices, 0], X_train[class0_indices, 1], color='mediumblue')\n",
    "    ax[i].scatter(X_train[class1_indices, 0], X_train[class1_indices, 1], color='firebrick')\n",
    "\n",
    "# contour0 = ax[0].contourf(xx, yy, Z0, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "contour1 = ax[1].contourf(xx, yy, Z1, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "# contour2 = ax[2].contourf(xx, yy, Z2, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "\n",
    "decision_boundary_prob = 0.5\n",
    "\n",
    "# boundary0 = ax[0].contour(xx, yy, Z0, levels=[decision_boundary_prob], colors='purple')\n",
    "boundary1 = ax[1].contour(xx, yy, Z1, levels=[decision_boundary_prob], colors='purple')\n",
    "# boundary2 = ax[2].contour(xx, yy, Z2, levels=[decision_boundary_prob], colors='purple')\n",
    "\n",
    "# cbar = fig.colorbar(contour2, ax=ax, orientation='vertical')\n",
    "# cbar.set_label('Probability of class 1')\n",
    "\n",
    "ax[0].set_title('DBC', fontsize=14)\n",
    "ax[1].set_title('PDBC with hard clustering', fontsize=14)\n",
    "ax[2].set_title('PDBC with soft clustering', fontsize=14)"
   ],
   "id": "39ab5bf3dd94259a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "DBC_kmeans.discretization_model.eval()\n",
    "DBC_kmeans.discretization_model.cpu()\n",
    "with torch.no_grad():\n",
    "    # 创建网格\n",
    "    padding=0.1\n",
    "    x_min, x_max = X_train[:, 0].min() - padding, X_train[:, 0].max() + padding\n",
    "    y_min, y_max = X_train[:, 1].min() - padding, X_train[:, 1].max() + padding\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),  # 可以调整步长来控制分辨率\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "    # 将网格点转换为张量\n",
    "    grid_points = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "\n",
    "    # 预测网格点的Profile Assignment\n",
    "    _, q_z_given_x_grid, _ = DBC_kmeans.discretization_model(grid_points).cpu().detach()\n",
    "    Z_grid_1 = torch.argmax(q_z_given_x_grid, dim=1)\n",
    "    Z_grid_1 = Z_grid_1.reshape(xx.shape)\n",
    "\n",
    "    # 预测训练数据的Profile Assignment用于对比\n",
    "    _, q_z_given_x, _ = DBC_kmeans.discretization_model(X_train)\n",
    "    Z_val_1 = torch.argmax(q_z_given_x, dim=1)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "# 使用contourf绘制颜色区域\n",
    "plt.contourf(xx, yy, Z_grid_1, levels=np.arange(DBC_kmeans.discretization_model.num_profiles + 1) - 0.5,\n",
    "             cmap=\"tab10\", alpha=0.6)\n",
    "# 在上面叠加训练数据点\n",
    "# plt.scatter(X_train[:, 0], X_train[:, 1], c=Z_val_1, cmap=\"tab10\",\n",
    "#            edgecolors='black', linewidth=0.5, s=20)\n",
    "# 在上面叠加训练数据点\n",
    "class_0_mask = (y_train == 0)\n",
    "class_1_mask = (y_train == 1)\n",
    "plt.scatter(X_train[class_0_mask, 0], X_train[class_0_mask, 1],\n",
    "           c='red', edgecolors='black', linewidth=0.5, s=20, label='Class 0')\n",
    "plt.scatter(X_train[class_1_mask, 0], X_train[class_1_mask, 1],\n",
    "           c='skyblue', edgecolors='black', linewidth=0.5, s=20, label='Class 1')\n",
    "plt.title(\"Learned Profile Assignment (Z) - Space Partition\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "# plt.colorbar(label='Profile')\n",
    "plt.show()"
   ],
   "id": "d4058ac5a07da363",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the Kmeans Discrete Bayesian Classifier with 10 clusters and a set random state for reproducibility\n",
    "DBC_kmeans = DiscriminativeMinmaxClassifier(n_clusters=15, random_state=25,n_epochs=300)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "DBC_kmeans.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = DBC_kmeans.predict(X_train)\n",
    "\n",
    "# Compute the conditional risk based on the true labels and predicted labels\n",
    "conditional_risk = compute_conditional_risk(y_train, y_pred)\n",
    "print(f'Class condition risk: \\n{conditional_risk[0]}')\n",
    "print(f'\\nConfusion matrix: \\n{conditional_risk[1]}')"
   ],
   "id": "1cd55c3ce1197044",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dbc.main import CmeansDiscreteMinmaxClassifier\n",
    "# Initialize the Kmeans Discrete Bayesian Classifier with 10 clusters and a set random state for reproducibility\n",
    "DBC_kmeans = CmeansDiscreteMinmaxClassifier(n_clusters=15, use_kmeans=True,fuzzifier=1.5)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "DBC_kmeans.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = DBC_kmeans.predict(X_train)\n",
    "\n",
    "# Compute the conditional risk based on the true labels and predicted labels\n",
    "conditional_risk = compute_conditional_risk(y_train, y_pred)\n",
    "print(f'Class condition risk: \\n{conditional_risk[0]}')\n",
    "print(f'\\nConfusion matrix: \\n{conditional_risk[1]}')"
   ],
   "id": "bb116b2e1c4aa1ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the Kmeans Discrete Bayesian Classifier with 10 clusters and a set random state for reproducibility\n",
    "DBC_kmeans = KmeansDiscreteBayesianClassifier(n_clusters=15, random_state=25)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "DBC_kmeans.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = DBC_kmeans.predict(X_train)\n",
    "\n",
    "# Compute the conditional risk based on the true labels and predicted labels\n",
    "conditional_risk = compute_conditional_risk(y_train, y_pred)\n",
    "print(f'Class condition risk: \\n{conditional_risk[0]}')\n",
    "print(f'\\nConfusion matrix: \\n{conditional_risk[1]}')"
   ],
   "id": "6ad595ad2c5d8883",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "accuracy_score(y_train, y_pred)",
   "id": "9af7b058f9f7e1c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict the probability distribution over classes for each sample in the training data\n",
    "DBC_kmeans.predict_prob(X_train)"
   ],
   "id": "b0ab99855b159a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the C-means Discrete Bayesian Classifier with 10 clusters\n",
    "# Set the fuzzifier to 1.5 and use the cluster centers from the DBC_kmeans classifier\n",
    "DBC_fcm = CmeansDiscreteBayesianClassifier(n_clusters=15, fuzzifier=1.5, cluster_centers=DBC_kmeans.cluster_centers, random_state=25)\n",
    "# DBC_fcm = CmeansDiscreteBayesianClassifier(n_clusters=15, fuzzifier=1.5)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "DBC_fcm.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = DBC_fcm.predict(X_train)\n",
    "\n",
    "# Compute and return the conditional risk based on the true labels and predicted labels\n",
    "conditional_risk = compute_conditional_risk(y_train, y_pred)\n",
    "print(f'Class condition risk: \\n{conditional_risk[0]}')\n",
    "print(f'\\nConfusion matrix: \\n{conditional_risk[1]}')"
   ],
   "id": "307dd568b4b8b2db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict the probability distribution over classes for each sample in the training data\n",
    "DBC_fcm.predict_prob(X_train)"
   ],
   "id": "1535779430947e74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot decision boundaries and probability contours for DBC, PDBC with hard clustering, and PDBC with soft clustering\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "vor = Voronoi(DBC_kmeans.cluster_centers)\n",
    "voronoi_plot_2d(vor, show_points=False, show_vertices=False, s=1, ax=ax[0])\n",
    "voronoi_plot_2d(vor, show_points=False, show_vertices=False, s=1, ax=ax[1])\n",
    "voronoi_plot_2d(vor, show_points=False, show_vertices=False, s=1, ax=ax[2])\n",
    "\n",
    "Z1 = DBC_kmeans.predict_prob(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z0 = np.zeros_like(Z1)\n",
    "\n",
    "max_indices = np.argmax(Z1, axis=1)\n",
    "\n",
    "rows = np.arange(Z1.shape[0])\n",
    "\n",
    "Z0[rows, max_indices] = 1.0\n",
    "\n",
    "Z1 = Z1[:, 1].reshape(xx.shape)\n",
    "Z0 = Z0[:, 1].reshape(xx.shape)\n",
    "\n",
    "Z2 = DBC_fcm.predict_prob(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z2 = Z2[:, 1].reshape(xx.shape)\n",
    "\n",
    "class0_indices = (y_train == 0)\n",
    "class1_indices = (y_train == 1)\n",
    "for i in range(3):\n",
    "    ax[i].scatter(X_train[class0_indices, 0], X_train[class0_indices, 1], color='mediumblue')\n",
    "    ax[i].scatter(X_train[class1_indices, 0], X_train[class1_indices, 1], color='firebrick')\n",
    "\n",
    "contour0 = ax[0].contourf(xx, yy, Z0, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "contour1 = ax[1].contourf(xx, yy, Z1, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "contour2 = ax[2].contourf(xx, yy, Z2, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "\n",
    "decision_boundary_prob = 0.5\n",
    "\n",
    "boundary0 = ax[0].contour(xx, yy, Z0, levels=[decision_boundary_prob], colors='purple')\n",
    "boundary1 = ax[1].contour(xx, yy, Z1, levels=[decision_boundary_prob], colors='purple')\n",
    "boundary2 = ax[2].contour(xx, yy, Z2, levels=[decision_boundary_prob], colors='purple')\n",
    "\n",
    "cbar = fig.colorbar(contour2, ax=ax, orientation='vertical')\n",
    "cbar.set_label('Probability of class 1')\n",
    "\n",
    "ax[0].set_title('DBC', fontsize=14)\n",
    "ax[1].set_title('PDBC with hard clustering', fontsize=14)\n",
    "ax[2].set_title('PDBC with soft clustering', fontsize=14)"
   ],
   "id": "34c970e8badf495b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot decision boundaries and probability contours for DBC, PDBC with hard clustering, and PDBC with soft clustering\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "vor = Voronoi(DBC_kmeans.cluster_centers)\n",
    "voronoi_plot_2d(vor, show_points=False, show_vertices=False, s=1, ax=ax[0])\n",
    "voronoi_plot_2d(vor, show_points=False, show_vertices=False, s=1, ax=ax[1])\n",
    "\n",
    "Z1 = DBC_kmeans.predict_prob(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z0 = np.zeros_like(Z1)\n",
    "\n",
    "max_indices = np.argmax(Z1, axis=1)\n",
    "\n",
    "rows = np.arange(Z1.shape[0])\n",
    "\n",
    "Z0[rows, max_indices] = 1.0\n",
    "\n",
    "Z1 = Z1[:, 1].reshape(xx.shape)\n",
    "Z0 = Z0[:, 1].reshape(xx.shape)\n",
    "\n",
    "Z2 = DBC_fcm.predict_prob(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z2 = Z2[:, 1].reshape(xx.shape)\n",
    "\n",
    "class0_indices = (y_train == 0)\n",
    "class1_indices = (y_train == 1)\n",
    "for i in range(2):\n",
    "    ax[i].scatter(X_train[class0_indices, 0], X_train[class0_indices, 1], color='mediumblue')\n",
    "    ax[i].scatter(X_train[class1_indices, 0], X_train[class1_indices, 1], color='firebrick')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "\n",
    "contour0 = ax[0].contourf(xx, yy, Z0, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "contour1 = ax[1].contourf(xx, yy, Z2, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "\n",
    "\n",
    "decision_boundary_prob = 0.5\n",
    "\n",
    "boundary0 = ax[0].contour(xx, yy, Z0, levels=[decision_boundary_prob], colors='purple')\n",
    "boundary1 = ax[1].contour(xx, yy, Z2, levels=[decision_boundary_prob], colors='purple')\n",
    "\n",
    "cbar = fig.colorbar(contour2, ax=ax, orientation='vertical')\n",
    "cbar.set_label('Probability of red class')\n",
    "\n",
    "ax[0].set_title('DBC', fontsize=14)\n",
    "ax[1].set_title('SPDBC', fontsize=14)\n",
    "\n",
    "plt.savefig(\"DBC_SPDBC.pdf\",dpi=300, bbox_inches=\"tight\",transparent=True)\n"
   ],
   "id": "abef21cb77fcbf25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DMC_kmeans = KmeansDiscreteMinimaxClassifier(n_clusters=15, random_state=25)\n",
    "DMC_kmeans.fit(X_train, y_train)\n",
    "y_pred = DMC_kmeans.predict(X_train)\n",
    "conditional_risk = compute_conditional_risk(y_train, y_pred)\n",
    "print(f'Class condition risk: \\n{conditional_risk[0]}')\n",
    "print(f'\\nConfusion matrix: \\n{conditional_risk[1]}')"
   ],
   "id": "180b48814f4717c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "vor = Voronoi(DMC_kmeans.cluster_centers)\n",
    "voronoi_plot_2d(vor, show_points=False, show_vertices=False, s=1, ax=ax[0])\n",
    "voronoi_plot_2d(vor, show_points=False, show_vertices=False, s=1, ax=ax[1])\n",
    "voronoi_plot_2d(vor, show_points=False, show_vertices=False, s=1, ax=ax[2])\n",
    "\n",
    "Z1 = DMC_kmeans.predict_prob(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z0 = np.zeros_like(Z1)\n",
    "\n",
    "max_indices = np.argmax(Z1, axis=1)\n",
    "\n",
    "rows = np.arange(Z1.shape[0])\n",
    "\n",
    "Z0[rows, max_indices] = 1.0\n",
    "\n",
    "Z1 = Z1[:, 1].reshape(xx.shape)\n",
    "Z0 = Z0[:, 1].reshape(xx.shape)\n",
    "\n",
    "Z2 = DBC_fcm.predict_prob(np.c_[xx.ravel(), yy.ravel()], prior_pred=DMC_kmeans.prior_star)\n",
    "Z2 = Z2[:, 1].reshape(xx.shape)\n",
    "\n",
    "class0_indices = (y_train == 0)\n",
    "class1_indices = (y_train == 1)\n",
    "for i in range(3):\n",
    "    ax[i].scatter(X_train[class0_indices, 0], X_train[class0_indices, 1], color='mediumblue')\n",
    "    ax[i].scatter(X_train[class1_indices, 0], X_train[class1_indices, 1], color='firebrick')\n",
    "\n",
    "contour0 = ax[0].contourf(xx, yy, Z0, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "contour1 = ax[1].contourf(xx, yy, Z1, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "contour2 = ax[2].contourf(xx, yy, Z2, alpha=0.7, cmap='coolwarm', levels=np.linspace(0, 1, 11))\n",
    "\n",
    "decision_boundary_prob = 0.5\n",
    "\n",
    "boundary0 = ax[0].contour(xx, yy, Z0, levels=[decision_boundary_prob], colors='purple')\n",
    "boundary1 = ax[1].contour(xx, yy, Z1, levels=[decision_boundary_prob], colors='purple')\n",
    "boundary2 = ax[2].contour(xx, yy, Z2, levels=[decision_boundary_prob], colors='purple')\n",
    "\n",
    "cbar = fig.colorbar(contour2, ax=ax, orientation='vertical')\n",
    "cbar.set_label('Probability of class 1')\n",
    "\n",
    "ax[0].set_title('DMC', fontsize=14)\n",
    "ax[1].set_title('PDMC with hard clustering', fontsize=14)\n",
    "ax[2].set_title('PDMC with soft clustering', fontsize=14)"
   ],
   "id": "b64b4d5e428d698d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DBC_DT = DecisionTreeDiscreteBayesianClassifier(max_depth=10)\n",
    "DBC_DT.fit(X_train, y_train)\n",
    "y_pred = DBC_DT.predict(X_train, prior_pred=DBC_DT.prior)\n",
    "conditional_risk = compute_conditional_risk(y_train, y_pred)\n",
    "print(f'Class condition risk: \\n{conditional_risk[0]}')\n",
    "print(f'\\nConfusion matrix: \\n{conditional_risk[1]}')"
   ],
   "id": "7cf754816726904",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "accuracy_score(y_train, y_pred)",
   "id": "30a14e7388d81459",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DMC_DT = DecisionTreeDiscreteMinimaxClassifier(max_depth=10)\n",
    "DMC_DT.fit(X_train, y_train)\n",
    "y_pred = DMC_DT.predict(X_train)\n",
    "conditional_risk = compute_conditional_risk(y_train, y_pred)\n",
    "print(f'Class condition risk: \\n{conditional_risk[0]}')\n",
    "print(f'\\nConfusion matrix: \\n{conditional_risk[1]}')"
   ],
   "id": "669c3aa64a064883",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
